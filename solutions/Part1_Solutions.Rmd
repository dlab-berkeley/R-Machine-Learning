---
title: "R Machine Learning Pilot Solutions (Day 1)"
output: html_notebook
---


## 📝 Poll 1: Machine Learning Questions

Which of these research applications are well suited for machine learning methods? Select all that apply.

1.  Diagnosing a patient's illness based on a cluster of symptoms and other health data.

2.  Explaining why some states have higher voter participation rates than others.

3.  Identifying likely voters in an upcoming election.

4.  Estimating the impact of unionization on worker pay.

5.  Predicting an individual's hourly wage based on demographic, economic, and geographic information.

**Solutions**: 1, 3, 5. Good news! We'll be covering how to address (3) and (5) in Parts 1 and 2 in this workshop!


## 🥊 Challenge 1: Predicting Wage from Age

Let's try to predict an individual's hourly wage based on their age alone using linear regression. We can plot variables to see the relationship with `ggplot2` and add a best fit line. Let's first examine the relationship between a worker's age (`age`) and their hourly wage (`hourly_wage`).

```{r}
jobs %>%
  ggplot(aes(x = age, y = hourly_wage)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm", color = "red", se = F) + 
  labs(title = "Scatter Plot of Age vs. Hourly Wage with Best Fit Line", 
       x = "Age", 
       y = "Hourly Wage") + 
  theme_minimal() 
```

## 🔔 Question 1: Terminology

Notice that we have called *y* the "outcome" or "target" variable, and the set of $\mathbf{X}$ variables "features" or "inputs." How does this language reflect a conceptual shift from traditional statistics and causal inference, where we typically use language like "independent" and "dependent" variables?

**Solution**: We are focused on predicting the value of y, and are moving away from traditional statistics by not making assumptions about the nature of the causal relationship between our x and our y.


## 🥊 Challenge 2: Exploratory Analyses

In Challenge 1, we looked at the relationship between a continuous x feature, `age`, and our target, `hourly_wage`. Perform your own exploratory analyses, but this time examine at least one categorical feature (or features) that you think might be useful in predicting `hourly_wage`. Which features seem most interesting to you? *Hint:* one way to explore continuous variables is by looking at overlapping histograms. Check out the documentation [here](https://ggplot2.tidyverse.org/reference/geom_histogram.html). 

```{r}
# Histogram of Wage by Full- or Part-time Status
jobs %>%
  ggplot(aes(x = hourly_wage, fill = worker_status)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
  labs(title = "Overlapping Histogram of Hourly Wage by Time Contract",
       x = "Wage",
       y = "Frequency",
       fill = "Full- or Part-Time Status") +
  theme_minimal()
```

## 🔔 Question 2: Data Types

What are the data types for these three variables? If you are familiar with linear regression, can you think of issues that might arise if we were to plug these variables into a regression model?

**Solution:** Looking at the first 10 rows, we see that `hours_weekly` is a numeric variable with missing values; `union` is a binary categorical variable with two values; and `state` is categorical variable with many values. Including `hours_weekly` will produce an error because linear regression cannot inherently handle missing values. As for `union` and `state`, regression models are mathematical models that operate on numerical data. Categorical variables represent qualities or characteristics that can't be directly quantified in a way that naturally fits into these models. Recoding transforms these qualitative attributes into a numerical format that the model can interpret and use.


## 🥊 Challenge 3: Assess Data Quality

Determine the extent to which missing values are a problem in this data set. *Hint*: try using the `colSums()` function. The documentation is available [here](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/colSums).

```{r}
colSums((is.na(jobs)))
```

🔔 **Question 2**: How does splitting our data into the training and test sets address the bias-variance trade-off described above?

**Answer**: This split is crucial for preventing overfitting, providing an unbiased evaluation of the model's performance, and ensuring that the model can make accurate predictions on data it has not encountered during training.


## 🥊 Challenge 4: Predicting Income

Train a model to predict an individual's income `total_indiv_income` on `jobs_train` and evaluate the model on `jobs_train`. Note that this is related to, but not a direct function of, one's wage because income can come from multiple sources (e.g., retirement savings, investment income).

First, create a recipe that gives a set of instructions for pre-processing.

```{r}
chal4_recipe <- 
  recipe(total_income ~ ., data = jobs) %>% # tell r what our outcome variable is 
  step_naomit(all_predictors()) %>% # drop records with missing values 
  step_dummy(all_nominal_predictors()) # create dummy variables from categorical variables
chal4_recipe
```

Next, create a workflow that applies our recipe (i.e., set of pre-processing instructions) and adds our linear model `model` that we initialized above.

```{r}
chal4_wflow <- workflow() %>% 
  add_recipe(chal4_recipe) %>% 
  add_model(model)
```

Our workflow now contains all of the steps and instructions to train the model. `add_recipe` has laid out the pre-processing instructions, and `add_model` has specified that we will use our linear regression model `model` to fit to the training data.

```{r}
# obtain predictions 
chal4_fit <- fit(chal4_wflow, jobs_train)
chal4_fit %>% tidy()
```

Deploy our fitted model `chal4_fit` on the test set `jobs_test` to see how well it did at predicting an individual's income.

```{r}
# Predict new observations of our model fit with augment() 
chal4_results <- augment(chal4_fit, jobs_test)

# Obtain R-squared
chal4_metrics <- metric_set(rmse, rsq, mae)
chal4_metrics(chal4_results, truth = total_income, estimate = .pred)
```
